#!/usr/bin/python
# vim: set ts=2 expandtab:
"""
Module: huplo-view-stream
Desc: Relay an existing video stream via a TCP server and allow text overlay
Author: John O'Neil
Email: oneil.john@gmail.com

Simple stream realy with text overlay.
Point the relay at an existing stream URL and we can relay it
via another TCP server.
Relaying like this (and transcoding to H264/MP3) allows us
to access the video and overlay dynamic text and graphics atop
the video.

"""

import sys, os
import pygtk
pygtk.require ("2.0")
import gtk
import gobject
gobject.threads_init()

import pygst
pygst.require('0.10')
import gst

from huplo.gstreamer import HeadsUpPresentatonLayer
from huplo.ticker import TickerManager
from huplo.text import TextManager
from huplo.list import ListManager
from huplo.chat_display import ChatManager
from huplo.animated_scrolling_queue import QueueManager as AnimatedQueueManager

import logging
import argparse

from math import pi

import dbus
import dbus.service

class StreamRelayWithTextOverlay(object):
  '''Relay a video+audio stream given its URL, with the option to overlay dynamic text
    on the stream contents.
    Has been tested on mpeg TS (h264/mp3) and .nsv (shoutcast) streams.
  '''
  def __init__(self, uri, display_name, host='127.0.0.1', port=10000):
    '''Initialize and start rendered gstreamer video stream with IRC overlay.
    Stream currently relayed as MPEG TS (h264/mp3)
    :param URI: URI address of video stream to render.
    :type URI: str.
    :param host: hostname for relayed stream tcp server
    :param port: port number for relayed stream tcp server 
    '''
    self.pipeline = gst.Pipeline(display_name)

    #primary source is URI decode bin, which can connect to stream
    #and provide us with audio/video demuxed streams on separate pads.
    #the pads appear to us as they're instantiated, via the demuxer callback
    self.uribin = gst.element_factory_make("uridecodebin","uribin")
    self.uribin.set_property("uri", uri )
    self.pipeline.add(self.uribin)
    self.uribin.connect("pad-added", self._demuxer_callback)

    #primary sink is a TCP server. Clients (like a VLC media player) can connect
    #to the set host:port to receive our mpeg TS output.
    #thus we instantiate a TSmux and TCP server at pipeline back end
    self.mux = gst.element_factory_make('mpegtsmux', 'mux')
    self.pipeline.add(self.mux)
    self.tcpserver = gst.element_factory_make("tcpserversink", "tcpserver")
    self.tcpserver.set_property("host", host)
    self.tcpserver.set_property('port', port)
    self.pipeline.add(self.tcpserver)
    self.mux.link(self.tcpserver)

    #our video pipeline is as follows
    # -->convert-->text_overlay-->convert-->h264-->queue-->mux
    #TODO: optimize this to do without conversion, queue or h264?
    self.convert1 = gst.element_factory_make("ffmpegcolorspace","convert1")
    self.pipeline.add(self.convert1)

    self.text = HeadsUpPresentatonLayer()
    self.text.add_overlay(TickerManager())
    self.text.add_overlay(TextManager())
    self.text.add_overlay(ListManager())
    self.text.add_overlay(ChatManager())
    self.text.add_overlay(AnimatedQueueManager(display_name))
    self.pipeline.add(self.text)

    self.convert2 = gst.element_factory_make("ffmpegcolorspace","convert2")
    self.pipeline.add(self.convert2)

    self.h264 = gst.element_factory_make("x264enc","h264")
    #self.h264.set_property("bitrate", 256)
    #self.h264.set_property("subme", 4)
    #self.h264.set_property("b-pryamid", True)
    #self.h264.set_property("weightb", True)
    self.pipeline.add(self.h264)

    self.video_queue = gst.element_factory_make("queue2","video_queue")
    self.pipeline.add(self.video_queue)

    self.convert1.link(self.text)
    self.text.link(self.convert2)
    self.convert2.link(self.h264)
    self.h264.link(self.video_queue)
    self.video_queue.link(self.mux)

    #construct audio queue elements, and hook into muxer
    #audio pipeline goes like:
    # -->audio_queue-->audioconv-->mp3enc-->mux
    self.audio_queue = gst.element_factory_make("queue2","audio_queue")
    self.pipeline.add(self.audio_queue)
    self.audioconv = gst.element_factory_make("audioconvert","audioconv")
    self.pipeline.add(self.audioconv)
    self.mp3enc = gst.element_factory_make("lamemp3enc", "mp3enc")
    self.pipeline.add(self.mp3enc)
    
    self.audio_queue.link(self.audioconv)
    self.audioconv.link(self.mp3enc)
    self.mp3enc.link(self.mux)
    
    #Hook up the bus and set pipeline running
    bus = self.pipeline.get_bus()
    bus.add_signal_watch()
    bus.connect("message", self._on_message)  
    self.pipeline.set_state(gst.STATE_PAUSED)
    self.pipeline.set_state(gst.STATE_PLAYING)

  def push(self, msg):
    ''' Push an IRCMessage into the current IRC queue.

    :param msg: The IRC message we'd like to push to the front of the current
      queue
    :type msg: IRCMessage.
    '''
    #for handler in self.DrawHandlers:
    #  handler.push(msg)
    pass

  def _demuxer_callback(self, uribin, pad):
    caps = pad.get_caps()
    name = caps[0].get_name()
    if(name == 'video/x-raw-rgb'):
      pad.link(self.convert1.get_pad('sink'))
    else:
      pad.link(self.audio_queue.get_pad('sink'))
    return True

  def OnMessage(self, message):
    #print '***client msg*** ' + message
    self.push(IRCMessage('UNKNOWN', 'vhost', message))

  def _on_message(self, bus, message):
    t = message.type
    if t == gst.MESSAGE_EOS:
      self.pipeline.set_state(gst.STATE_NULL)
      print "message EOS"
      gtk.main_quit()
    elif t == gst.MESSAGE_ERROR:
      self.pipeline.set_state(gst.STATE_NULL)
      err, debug = message.parse_error()
      print "Error: %s" % err, debug
      gtk.main_quit()


def main():
  usage = 'usage: --url <stream url> --display <display name>'
  parser = argparse.ArgumentParser(description=usage)
  parser.add_argument("-s", "--stream", dest="STREAM_URL",
                      help="stream URL to open")
  parser.add_argument("-d", "--display", dest="DISPLAY_NAME",
                      help="display name. Clients can attach text displays via this friendlyname.", default='')
  parser.add_argument("-v", "--verbose",
                      action="store_true", dest="verbose")
  parser.add_argument("-q", "--quiet",
                      action="store_false", dest="verbose")
  args = parser.parse_args()
  if not args.STREAM_URL:
    parser.error(usage)
  if args.verbose:
    logging.basicConfig(level=logging.DEBUG)

  dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)

  stream = StreamRelayWithTextOverlay(args.STREAM_URL, args.DISPLAY_NAME)

  gtk.main()
  

if __name__ == "__main__":
  main()

